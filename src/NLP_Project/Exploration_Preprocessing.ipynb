{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01740351-2b24-46a4-88b6-6cbdec7239b8",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a0b14c-f5e1-431d-bff0-8dcc51d12230",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import re\n",
    "\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from datasets import load_dataset\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab33ba6b-2a35-4c82-96bd-311869715936",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.monospace\"] = [\"DejaVu Sans Mono\"]\n",
    "plt.rcParams[\"font.family\"] = \"monospace\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12205200-293a-4e31-b3ca-a60d59eefc3f",
   "metadata": {},
   "source": [
    "#### NLP analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915594f1-5648-4291-bf73-a17c56fa7e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"ML-Projects-Kiel/tweetyface\", \"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222d72b2-8e1e-4d46-bb88-aa107d16cfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f44179-51b1-42c5-a167-795fdc0e700d",
   "metadata": {},
   "source": [
    "Combine the train and validation dataset to one DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501159f9-81f4-4d6a-b5aa-6718514dc515",
   "metadata": {},
   "outputs": [],
   "source": [
    "_df_dict = dict()\n",
    "for _data_set in [\"train\", \"validation\"]:\n",
    "    _df_dict[_data_set] = pd.DataFrame(\n",
    "        {\"label\": dataset[_data_set][\"label\"], \"text\": dataset[_data_set][\"text\"]}\n",
    "    )\n",
    "df = pd.concat([_df_dict[\"train\"], _df_dict[\"validation\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72ecefd-98c9-470f-b116-d9746158555b",
   "metadata": {},
   "source": [
    "Create DataFrame for unigrams and pos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3330b889-37c6-47ed-a1b9-57fadec8fbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a263dc6-1395-4cc2-9977-1e9a249ce6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_pos(doc) -> list:\n",
    "    return [token.pos_ for token in doc]\n",
    "\n",
    "\n",
    "def return_words(doc) -> list:\n",
    "    return [token.lemma_ for token in doc]\n",
    "\n",
    "\n",
    "def remove_stops(doc) -> list:\n",
    "    return [\n",
    "        token.lemma_\n",
    "        for token in doc\n",
    "        if not token.is_stop\n",
    "        if not token.is_punct\n",
    "        if not token.is_space\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f577187-092a-4527-9978-cb9047f11585",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = list()\n",
    "for _user in tqdm(set(df[\"label\"])):\n",
    "    user_df = df[df[\"label\"] == _user].copy()\n",
    "    # Preprocess steps\n",
    "    user_df[\"text\"] = [re.sub(\"\\n\", \" \", txt) for txt in user_df[\"text\"]]\n",
    "    user_df[\"text\"] = [re.sub(r\"http\\S+\", \"URL\", txt) for txt in user_df[\"text\"]]\n",
    "    user_df[\"text\"] = [re.sub(\"&amp;\", \"&\", txt) for txt in user_df[\"text\"]]\n",
    "    user_df[\"text\"] = [\" \".join(txt.split()) for txt in user_df[\"text\"]]\n",
    "\n",
    "    docs = [nlp(txt) for txt in user_df[\"text\"]]\n",
    "    _df = pd.DataFrame({\"label\": itertools.repeat(_user, user_df.shape[0])})\n",
    "    _df[\"pos\"] = list(map(return_pos, docs))\n",
    "    _df[\"words\"] = list(map(return_words, docs))\n",
    "    _df[\"words_nostops\"] = list(map(remove_stops, docs))\n",
    "    df_list.append(_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f40d46c-66dd-4af2-8625-bd4831cefc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef9d45d-841f-4201-8692-93f091610d50",
   "metadata": {},
   "source": [
    "#### Dict to translate labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ab47b8-0393-45b5-ab3f-317ec8d4e55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_features = dataset[\"train\"].features[\"label\"].names  # Create List with all users\n",
    "label_translation = {idx: label for idx, label in enumerate(full_features)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd07678-4a8a-4db8-84e4-23313114a572",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846c7f76-1391-463e-bb66-fd924d981752",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"] = df[\"label\"].replace(label_translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b1c9a6-5a46-4762-a137-d6a7850f8a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872f17be-27f1-4e11-ad7d-ee68455da75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_tweets = pd.DataFrame(df.groupby(\"label\").size()).reset_index().rename(columns={0: \"tweets\"})\n",
    "total_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddbc276-7cc0-4f21-8c2e-6d09fdbab46b",
   "metadata": {},
   "source": [
    "#### Inspects POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb98a1a-ac6d-42f1-9ba7-924f315c4339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode_df(df, _key):\n",
    "    df_pos = (\n",
    "        df.reset_index()\n",
    "        .explode(_key)[[\"index\", \"label\", _key]]\n",
    "        .groupby([\"index\", \"label\", _key])\n",
    "        .size()\n",
    "        .reset_index(name=\"counts\")\n",
    "    )\n",
    "    return pd.pivot(df_pos, index=[\"index\", \"label\"], columns=_key, values=\"counts\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e378f391-32ec-416e-befe-c50239de9dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos = explode_df(df, \"pos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc2420e-31b6-4341-bed5-0c0f173bd6e5",
   "metadata": {},
   "source": [
    "Create grouped POS DF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a997e6-50c5-4640-955f-e953a16a1f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos_group = df_pos.groupby(\"label\").sum().drop(columns=\"index\").reset_index()\n",
    "df_pos_group[\"total\"] = df_pos_group.iloc[:, 1:].sum(axis=1)\n",
    "df_pos_group = pd.merge(df_pos_group, total_tweets, on=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed2a6ad-d287-4de9-b607-712db5dea5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(df_pos_group, y=\"label\", x=\"total\")\n",
    "plt.ylabel(\"Twitter User\")\n",
    "plt.xlabel(\"Number of total tokens\")\n",
    "plt.title(\"Total tokens per Twitter User\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331b9108-e1f8-45e6-865c-0b835932a914",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos_group[\"num_per_tweet\"] = df_pos_group[\"total\"] / df_pos_group[\"tweets\"]\n",
    "sns.barplot(df_pos_group, y=\"label\", x=\"num_per_tweet\")\n",
    "plt.ylabel(\"Twitter User\")\n",
    "plt.xlabel(\"Tokens per Tweet\")\n",
    "plt.title(\"Tokens per Tweet per Twitter User\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364a64e1-91c8-40c3-a634-83162d1b7e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos_t = pd.melt(\n",
    "    df_pos_group,\n",
    "    id_vars=[\"label\", \"total\"],\n",
    "    value_vars=df_pos_group.columns[1:-3],\n",
    "    var_name=\"POS\",\n",
    "    value_name=\"num_per_tweet\",\n",
    "    ignore_index=True,\n",
    ").sort_values(by=[\"POS\"])\n",
    "df_pos_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb060453-45f7-42dc-b148-b436c7efcceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows, ncols = 3, 4\n",
    "fig, axes = plt.subplots(figsize=(20, 10), nrows=nrows, ncols=ncols)\n",
    "row, col = 0, 0\n",
    "for label in set(df_pos_t[\"label\"]):\n",
    "    ax = axes[row, col]\n",
    "    sns.barplot(df_pos_t[df_pos_t[\"label\"] == label], y=\"POS\", x=\"num_per_tweet\", ax=ax)\n",
    "    ax.set_title(label)\n",
    "    col += 1\n",
    "    if col == ncols:\n",
    "        row += 1\n",
    "        col = 0\n",
    "plt.tight_layout()\n",
    "# plt.title(\"Percentages of part-of-speech tags (POS) per User\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b63ecc-7eeb-4c99-8a31-e3e3bb1b97d2",
   "metadata": {},
   "source": [
    "#### Inspect Unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6073c85a-03f2-4e64-9530-e2fca7d43153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode_df_unigram(df, _key):\n",
    "    _df = (\n",
    "        df.reset_index()\n",
    "        .explode(_key)[[\"index\", \"label\", _key]]\n",
    "        .groupby([\"index\", \"label\", _key])\n",
    "        .size()\n",
    "        .reset_index(name=\"counts\")\n",
    "    )\n",
    "    return _df.drop(columns=\"index\").groupby([\"label\", _key]).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b096f65f-7fba-4612-9078-174e2e7ed16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uni = explode_df_unigram(df, \"words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e84ca65-814e-4f4e-ac7d-0e12dbe84106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_uni_bar(df, key):\n",
    "    nrows, ncols = 3, 4\n",
    "    fig, axes = plt.subplots(figsize=(20, 10), nrows=nrows, ncols=ncols)\n",
    "    row, col = 0, 0\n",
    "    for label in set(df[\"label\"]):\n",
    "        ax = axes[row, col]\n",
    "        _df = df[df[\"label\"] == label].nlargest(20, \"counts\")\n",
    "        labels = _df[key].to_list()\n",
    "        sns.barplot(_df, x=key, y=\"counts\", ax=ax)\n",
    "        ax.set_title(label)\n",
    "        ax.set_xticklabels(labels, rotation=45, ha=\"right\")\n",
    "        ax.set_xlabel(\"Unigrams\")\n",
    "        ax.set_ylabel(\"Amount\")\n",
    "        col += 1\n",
    "        if col == ncols:\n",
    "            row += 1\n",
    "            col = 0\n",
    "    plt.tight_layout()\n",
    "    # plt.title(\"Percentages of part-of-speech tags (POS) per User\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fa45b2-8e61-4874-abc6-98ced793d69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_uni_bar(df_uni, \"words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25020576-671a-42cb-b998-4c7aa5fb10b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uni_nostop = explode_df_unigram(df, \"words_nostops\")\n",
    "plot_uni_bar(\n",
    "    df_uni_nostop[\n",
    "        (df_uni_nostop[\"words_nostops\"] != \"url\") & (df_uni_nostop[\"words_nostops\"] != \"URL\")\n",
    "    ],\n",
    "    \"words_nostops\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b198019-7180-4a25-b234-5afa9e98d4ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenCampusNLP",
   "language": "python",
   "name": "opencampusnlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
